{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "The following table indicates the number of 6-point scores in an American rugby match in the 1979 season.\n",
    "\n",
    "![](table1.png)\n",
    "\n",
    "Based on these results, we create a Poisson distribution with the sample mean parameter  = 2.435. Is there any reason to believe that at a .05 level the number of scores is a Poisson variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.0036506742079480473",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m poisson \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mpoisson(\u001b[38;5;241m2.435\u001b[39m)\n\u001b[0;32m      3\u001b[0m E \u001b[38;5;241m=\u001b[39m [poisson\u001b[38;5;241m.\u001b[39mpmf(x)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m448\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)]\n\u001b[1;32m----> 5\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchisquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:7311\u001b[0m, in \u001b[0;36mchisquare\u001b[1;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[0;32m   7187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchisquare\u001b[39m(f_obs, f_exp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   7188\u001b[0m     \u001b[38;5;124;03m\"\"\"Calculate a one-way chi-square test.\u001b[39;00m\n\u001b[0;32m   7189\u001b[0m \n\u001b[0;32m   7190\u001b[0m \u001b[38;5;124;03m    The chi-square test tests the null hypothesis that the categorical data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7309\u001b[0m \n\u001b[0;32m   7310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 7311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpower_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7312\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:7153\u001b[0m, in \u001b[0;36mpower_divergence\u001b[1;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[0;32m   7147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff_gt_tol:\n\u001b[0;32m   7148\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor each axis slice, the sum of the observed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7149\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequencies must agree with the sum of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7150\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected frequencies to a relative tolerance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7151\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the percent differences are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7152\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   7155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7156\u001b[0m     \u001b[38;5;66;03m# Ignore 'invalid' errors so the edge case of a data set with length 0\u001b[39;00m\n\u001b[0;32m   7157\u001b[0m     \u001b[38;5;66;03m# is handled without spurious warnings.\u001b[39;00m\n\u001b[0;32m   7158\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.0036506742079480473"
     ]
    }
   ],
   "source": [
    "O = [35, 99, 104, 110, 62, 25, 10, 3]\n",
    "poisson = st.poisson(2.435)\n",
    "E = [poisson.pmf(x)*448 for x in range(8)]\n",
    "\n",
    "st.chisquare(O, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS/OPTIONAL - Question 2\n",
    "Let's analyze a discrete distribution. To analyze the number of defective items in a factory in the city of Medellín, we took a random sample of n = 60 articles and observed the number of defectives in the following table:\n",
    "\n",
    "![](table2.png)\n",
    "\n",
    "A poissón distribution was proposed since it is defined for x = 0,1,2,3, .... using the following model:\n",
    "\n",
    "![](image1.png)\n",
    "\n",
    "For some extra insights check the following link: https://online.stat.psu.edu/stat504/node/63/ \n",
    "\n",
    "Does the distribution of defective items follow this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS/OPTIONAL - Question 3\n",
    "A quality control engineer takes a sample of 10 tires that come out of an assembly line, and would like to verify on the basis of the data that follows, if the number of tires with defects observed over 200 days, if it is true that 5% of all tires have defects (that is, if the sample comes from a binomial population with n = 10 and p = 0.05). \n",
    "\n",
    "![](table3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "A researcher gathers information about the patterns of Physical Activity of children in the fifth grade of primary school of a public school. He defines three categories of physical activity (Low, Medium, High). He also inquires about the regular consumption of sugary drinks at school, and defines two categories (Yes = consumed, No = not consumed). We would like to evaluate if there is an association between patterns of physical activity and the consumption of sugary drinks for the children of this school, at a level of 5% significance. The results are in the following table: \n",
    "\n",
    "![](table4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.712198008709638,\n",
       " 0.004719280137040844,\n",
       " 2,\n",
       " array([[24.08421053, 19.70526316,  8.21052632],\n",
       "        [19.91578947, 16.29473684,  6.78947368]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer here\n",
    "observed = np.array([[32, 14, 6], [12, 22, 9]])\n",
    "st.chi2_contingency(observed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

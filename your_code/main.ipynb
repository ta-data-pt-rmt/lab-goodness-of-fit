{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "The following table indicates the number of 6-point scores in an American rugby match in the 1979 season.\n",
    "\n",
    "![](table1.png)\n",
    "\n",
    "Based on these results, we create a Poisson distribution with the sample mean parameter  = 2.435. Is there any reason to believe that at a .05 level the number of scores is a Poisson variable?\n",
    "\n",
    "Check [here](https://www.geeksforgeeks.org/how-to-create-a-poisson-probability-mass-function-plot-in-python/) how to create a poisson distribution and how to calculate the expected observations, using the probability mass function (pmf). \n",
    "A Poisson distribution is a discrete probability distribution. It gives the probability of an event happening a certain number of times (k) within a given interval of time or space. The Poisson distribution has only one parameter, Î» (lambda), which is the mean number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.0036506742079480473",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m expected_frequencies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(expected_probabilities) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(number_of_times)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 4: Perform the Hypothesis Test (Chi-squared test)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m chi_squared_statistic, p_value \u001b[38;5;241m=\u001b[39m chisquare(f_obs\u001b[38;5;241m=\u001b[39mnumber_of_times, f_exp\u001b[38;5;241m=\u001b[39mexpected_frequencies)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Step 5: Make a Decision\u001b[39;00m\n\u001b[0;32m     21\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ruoxi\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:7553\u001b[0m, in \u001b[0;36mchisquare\u001b[1;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[0;32m   7428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchisquare\u001b[39m(f_obs, f_exp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   7429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate a one-way chi-square test.\u001b[39;00m\n\u001b[0;32m   7430\u001b[0m \n\u001b[0;32m   7431\u001b[0m \u001b[38;5;124;03m    The chi-square test tests the null hypothesis that the categorical data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7551\u001b[0m \n\u001b[0;32m   7552\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 7553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m power_divergence(f_obs, f_exp\u001b[38;5;241m=\u001b[39mf_exp, ddof\u001b[38;5;241m=\u001b[39mddof, axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   7554\u001b[0m                             lambda_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ruoxi\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:7394\u001b[0m, in \u001b[0;36mpower_divergence\u001b[1;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[0;32m   7388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff_gt_tol:\n\u001b[0;32m   7389\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor each axis slice, the sum of the observed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7390\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequencies must agree with the sum of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7391\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected frequencies to a relative tolerance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7392\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the percent differences are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7393\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   7396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7397\u001b[0m     \u001b[38;5;66;03m# Ignore 'invalid' errors so the edge case of a data set with length 0\u001b[39;00m\n\u001b[0;32m   7398\u001b[0m     \u001b[38;5;66;03m# is handled without spurious warnings.\u001b[39;00m\n\u001b[0;32m   7399\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.0036506742079480473"
     ]
    }
   ],
   "source": [
    "#To determine whether the number of 6-point scores in an American rugby match in the 1979 season follows a Poisson distribution, we can perform a hypothesis test. \n",
    "#The null hypothesis (H0) is that the data follows a Poisson distribution, and the alternative hypothesis (H1) is that it does not.\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "number_of_scores = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "number_of_times = [35, 99, 104, 110, 62,25, 10, 3]\n",
    "\n",
    "# Step 2: \n",
    "sample_mean = 2.435\n",
    "# Step 3: Calculate the Expected Probabilities using poisson.pmf()\n",
    "expected_probabilities = [poisson.pmf(score, sample_mean) for score in number_of_scores]\n",
    "# Normalize the expected frequencies\n",
    "expected_frequencies = np.array(expected_probabilities) * np.sum(number_of_times)\n",
    "\n",
    "# Step 4: Perform the Hypothesis Test (Chi-squared test)\n",
    "chi_squared_statistic, p_value = chisquare(f_obs=number_of_times, f_exp=expected_frequencies)\n",
    "# Step 5: Make a Decision\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is evidence to suggest that the data does not follow a Poisson distribution.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant evidence to suggest that the data does not follow a Poisson distribution.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "A researcher gathers information about the patterns of Physical Activity of children in the fifth grade of primary school of a public school. He defines three categories of physical activity (Low, Medium, High). He also inquires about the regular consumption of sugary drinks at school, and defines two categories (Yes = consumed, No = not consumed). We would like to evaluate if there is an association between patterns of physical activity and the consumption of sugary drinks for the children of this school, at a level of 5% significance. The results are in the following table: \n",
    "\n",
    "![](table4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=10.712198008709638, pvalue=0.013388412365655075, dof=3, expected_freq=array([[24.08421053, 19.91578947],\n",
       "       [19.70526316, 16.29473684],\n",
       "       [ 8.21052632,  6.78947368],\n",
       "       [52.        , 43.        ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer here\n",
    "# null hypothesis is that there is no association between patterns of physical activity and the consumption of sugary drinks\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "table = [\n",
    "    [32, 12],\n",
    "    [14, 22],\n",
    "    [6, 9],\n",
    "    [52, 43]\n",
    "]\n",
    "st.chi2_contingency(np.array(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_value is lower than 0.05, the null hypothesis is rejected, which means that there is association between patterns of physical activity and the consumption of sugary drinks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
